\documentclass[11pt]{article}

\input{$HOME/imajin/preamble.tex}

\begin{document}

\lstset{language=C++,basicstyle=\footnotesize\ttfamily,breaklines=true}

\fancyhf{}
\fancyhead[R]{Derek Chong (derekch), Matthew Jin (mjin2002)}
\setlength{\headheight}{14pt}
\pagestyle{fancy}

\centerline{\Large CS 149: Programming Assignment 3}
\centerline{Autumn 2024-25}

\section{SAXPY}

\begin{lstlisting}
---------------------------------------------------------
Found 1 CUDA devices
Device 0: NVIDIA T4G
   SMs:    	40
   Global mem: 14918 MB
   CUDA Cap:   7.5
---------------------------------------------------------
Running 3 timing tests:
saxpy_kernel inner runtime: 4.930 ms        	[226.689 GB/s]
Effective BW by CUDA saxpy: 372.437 ms      	[3.001 GB/s]
saxpy_kernel inner runtime: 4.860 ms        	[229.940 GB/s]
Effective BW by CUDA saxpy: 393.690 ms      	[2.839 GB/s]
saxpy_kernel inner runtime: 4.862 ms        	[229.876 GB/s]
Effective BW by CUDA saxpy: 393.666 ms      	[2.839 GB/s]
\end{lstlisting}

\bigskip
{\it What performance do you observe compared to the sequential CPU-based
implementation of SAXPY (recall your results from saxpy on Program 5 from
Assignment 1)?}

\smallskip
Sequential CPU SAXPY with ISPC performed at around 27 GB/s, which is between
inner and outer runtime performance. This implies that due to the bottleneck
created by the memory bus, CUDA performance gains are really only possible if
the ratio of processing to data is high.

\medskip
{\it Compare and explain the difference between the results provided by two sets of timers (timing only the kernel execution vs. timing the entire process of moving data to the GPU and back in addition to the kernel execution) Are the bandwidth values observed roughly consistent with the reported bandwidths available to the different components of the machine?}

\begin{itemize}
  \item Inner timers report 5 ms, or 230 GB/s
  \item Outer timers report 390 ms, or 2.8 GB/s
  \item This is roughly consistent with the reported bandwidth available to the
    different components of the machine.
  \item NVIDIA T4 GPU datasheet quotes memory bandwidth at 300GB/s. Inner timers
    are bottlenecked by data movement within the GPU.
  \item Question text states that the expected memory bus bandwidth is 5.3GB/s.
    Outer timers bottleneck on movement across the memory bus.
  \item Performance losses of 77\% and 52\% are not unreasonable in practice, as
    these are subject to overhead (protocol, error correction, etc.) and have
    not been optimized (e.g. memory pinning).
\end{itemize}

\newpage
\section{Renderer}

\begin{lstlisting}
------------
Score table:
------------
--------------------------------------------------------------------------
| Scene Name      | Ref Time (T_ref) | Your Time (T)   | Score           |
--------------------------------------------------------------------------
| rgb             | 0.2663           | 0.2066          | 9               |
| rand10k         | 2.7453           | 1.8732          | 9               |
| rand100k        | 26.0927          | 19.0838         | 9               |
| pattern         | 0.359            | 0.2731          | 9               |
| snowsingle      | 16.1196          | 8.3193          | 9               |
| biglittle       | 14.9144          | 13.1142         | 9               |
| rand1M          | 187.1744         | 130.7247        | 9               |
| micro2M         | 356.142          | 232.0895        | 9               |
--------------------------------------------------------------------------
|                                    | Total score:    | 72/72           |
--------------------------------------------------------------------------
\end{lstlisting}

The above table was generated by running on an AWS g5g.xlarge instance which
uses the Amazon Graviton2 processor and the NVIDIA T4G Tensor Core GPU.

\paragraph{Implementation Summary}
We implemented a three phase solution.
\begin{enumerate}
  \item First, workers process circles in parallel, associating them to image
    patches they need to be drawn in
  \item We next use an exclusive prefix sum to reorganize results by patch
    location and distribute this across the worker pool.
  \item Finally, workers process patches of pixels in parallel, working through
    each patch’s circles in order to satisfy the ordering requirement.
\end{enumerate}

\paragraph{Implementation Description} Our solution partitions the input canvas
into smaller squares, each handled by a block of $32 \times 32$ threads. First,
each block partitions the input circle list evenly among its threads so each
thread processes $\frac{\ttt{len(input)}}{32 \times 32}$ circles (with the last
thread in the block processing less if the input length is not a multiple of
1024). Each thread then checks whether or not their assigned circles are
contained within their parent block using \ttt{circleInBox}. If a circle does
intersect the box, it is appended into a \ttt{circleIndexThread} array that is
stored in shared memory. The total number of intersecting circles processed by
the thread is stored in \ttt{prefixSumInput[index]} where \ttt{index} is the
thread's linear thread index in the block. A thread \tc{red}{sync} occurs here
to ensure that \ttt{prefixSumInput} has all array lengths stored properly
before proceeding to the next step.

\smallskip
We then perform a prefix sum over \ttt{prefixSumInput} to calculate the total
number of circles intersecting the block. A \tc{red}{sync} occurs after the call
to \ttt{sharedMemExclusiveScan} to ensure that \ttt{prefixSumOutput} is
correctly populated. The prefix sum allows us to collect all the circles
intersecting the block into another shared memory array \ttt{circleIndexBlock}
as \ttt{prefixSumOutput[index]} contains the index of where the corresponding
thread should start storing the circles it processed (sum of ``previous"
threads' \ttt{circleIndexThread} lengths). A thread \tc{red}{sync} occurs here
to ensure that everything is written to \ttt{prefixSumOutput}.

\smallskip
Now, we start drawing to the canvas. At this step, each thread now represents a
pixel and loops through each circle intersecting the block
(\ttt{circleIndexBlock}), shading each pixel sequentially via the provided
formula. 

\paragraph{Optimizations} An optimization at the last step is to read the
starting pixel color into a register which we use as a local accumulator for
calculating the new color. At the end of all the coloring, this value is finally
written back to the canvas in global memory. This reduces the amount of global
memory accesses which can slow down performance. In addition, another step we
took to reduce communication requirements was to put the prefix sum and circle
data in shared memory. Since each block operates on its own independent portion
of the canvas and processes the entire list of circles, the results of those
computations can be stored in shared memory which is much faster than global
memory. We also ran NVIDIA NSight and scanned profiler results for unusual
slowdowns, such as warp stalls. We identified a few minor optimizations around
setting out memory loads to help the compiler load via broadcast instead of
memory serialization.

\paragraph{How we arrived at our final solution} Our initial solution to
Question 3.1 was to swap the inner for loop, i.e. move from parallelizing over
circles to parallelizing over pixels. We quickly discovered that while this
conferred atomicity and ordering, it resulted in unacceptably high load
imbalance for complex scenes, as image patches varied significantly in how many
circles they contained. By contrast, circles did not generally vary greatly in
size.

\smallskip
We examined several hybrid solutions for managing the dual dimensions of
parallelism (pixels and circles), such as building a “superscalar processor” to
identify non-intersecting circles and parallelize over every pixel. Some options
were excluded due to being more recent than CUDA Compute Capability 8.0, such as
dynamic parallelism.

\smallskip
We also felt it might be interesting to implement the persistent thread pattern
“hack” that Kayvon shared in class. This seemed to fit the problem well: it
offers flexibility within the GPU without requiring any transfers back through
the memory bus.  We managed to get this running with full correctness, but ran
out of time to optimize. Managing communication effectively between control and
worker threads at scale was particularly challenging due to the limited atomic
primitives available in CUDA Compute Capability 8.0 (the Assignment 3 platform
version). More recent CUDA releases support much richer atomicity and
synchronisation capabilities, and this design was challenging in their absence.
Performance remained low after implementing a distributed queue and having
workers own 64-256 threads each. We finally opted to focus on a less unusual
solution.

\paragraph{Miscellaneous} Profiling CUDA with Nsight and timing code revealed
that our circle preprocessing stage was unexpectedly costly relative to drawing.
Our design had each block check each circle, which resulted in polynomial
slowdown. We are in the process of replacing this with a Thrust preprocessing
phase using data parallel programming patterns.


\end{document}
